name: Get data
inputs:
- {name: project_id, type: String}
- {name: bq_table, type: String}
outputs:
- {name: train_dataset, type: Dataset}
- {name: test_dataset, type: Dataset}
- {name: train_lables, type: Dataset}
- {name: test_lables, type: Dataset}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'pyarrow' 'scikit-learn==1.0.2' 'fsspec' 'gcsfs' 'google-cloud-bigquery' 'db_dtypes' 'google-cloud-storage' 'kfp==1.8.18' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def get_data(
          project_id: str,
          bq_table: str,
          train_dataset: Output[Dataset],
          test_dataset: Output[Dataset],
          train_lables: Output[Dataset],
          test_lables: Output[Dataset],
      ):
          import pandas as pd
          import logging
          import numpy as np
          import json

          from sklearn.model_selection import train_test_split
          from google.cloud import bigquery
          from google.cloud import storage

          logging.info("Downloading training data from BigQuery: {}, {}".format(project_id, bq_table))
          logging.info("Creating BigQuery client")
          bqclient = bigquery.Client(project=project_id)

          logging.info("Loading table data")
          table = bigquery.TableReference.from_string(bq_table)
          rows = bqclient.list_rows(table)
          dataframe = rows.to_dataframe()

          logging.info("Preparing data for training")
          dataframe["isFraud"] = dataframe["isFraud"].astype(int)
          dataframe.drop(['nameOrig','nameDest','isFlaggedFraud'],axis=1,inplace=True)
          X = pd.concat([dataframe.drop('type', axis=1), pd.get_dummies(dataframe['type'])], axis=1)
          y = X[['isFraud']]
          X = X.drop(['isFraud'],axis=1)

          print("Splitting data for training")
          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=42, shuffle=True)

          logging.info("Saving data")
          X_train.to_csv(train_dataset.path + ".csv" , index=False, encoding='utf-8-sig')
          X_test.to_csv(test_dataset.path + ".csv" , index=False, encoding='utf-8-sig')
          y_train.to_csv(train_lables.path + ".csv" , index=False, encoding='utf-8-sig')
          y_test.to_csv(test_lables.path + ".csv" , index=False, encoding='utf-8-sig')

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - get_data
