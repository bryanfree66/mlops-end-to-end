{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81ab15f-f995-4ea8-a96f-0d2f16613ac2",
   "metadata": {},
   "source": [
    "# MLOps Stage 3: Automation: Creating a Kubeflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd633a-0918-48df-abd1-78e36c3a7cc8",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d8232-1195-4a3a-908a-6a1172ac6455",
   "metadata": {},
   "source": [
    "In this notebook, we create a Vertex AI Pipeline for training and deploying a XGBoost model, and using Vertex AI Experiments to log training parameters and metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f68c2c-526d-4a86-9027-8ee6073c8479",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553cfe6d-c7d0-430f-92da-37fe1dc0ca11",
   "metadata": {},
   "source": [
    "Here, we use prebuilt components in Vertex AI Pipelines for training and deploying a XGBoost custom model, and using Vertex AI Experiments to log the corresponding training parameters and metrics, from within the training package.\n",
    "\n",
    "This notebook uses the following Google Cloud ML services:\n",
    "- Google Cloud Pipeline Components\n",
    "- Vertex AI Training\n",
    "- Vertex AI Pipelines\n",
    "- Vertex AI Experiments\n",
    "\n",
    "The steps performed include:\n",
    "- Construct a XGBoost training package.\n",
    "- Add tracking the experiment\n",
    "    - Construct a pipeline to train and deploy a XGBoost model.\n",
    "- Execute the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894cf5d-4f27-4836-b97d-4ddf435b8776",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec434f-8933-40a8-9d39-e13e60cb1183",
   "metadata": {},
   "source": [
    "The dataset used in this example is the Synthetic Financial Fraud dataset from Kaggle. PaySim simulates mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country. The original logs were provided by a multinational company, who is the provider of the mobile financial service which is currently running in more than 14 countries all around the world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c26dd5-5c11-4f42-90c8-18b55961c8f4",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bee4c-bbe4-4d9a-979b-63c182644193",
   "metadata": {},
   "source": [
    "Install the following packages for executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "018a1a14-6c84-4948-ad70-0f1992e3ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1822af21-ccd2-4f1a-8ad4-143213af3314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /home/jupyter/.local/lib/python3.7/site-packages (1.20.0)\n",
      "Requirement already satisfied: google-cloud-pipeline-components in /home/jupyter/.local/lib/python3.7/site-packages (1.0.32)\n",
      "Requirement already satisfied: kfp in /home/jupyter/.local/lib/python3.7/site-packages (1.8.18)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.33.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.6.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.22.1)\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-aiplatform) (2.34.4)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: google-cloud-notebooks>=0.4.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-pipeline-components) (1.4.4)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (8.1.3)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (1.12.11)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.1 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.7.4 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (4.4.0)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.16 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (0.1.16)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: kubernetes<20,>=8.0.0 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (0.15)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (2.1.0)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (0.10.1)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (0.7.0)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (1.8.5)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.10.2)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (1.3.0)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp) (4.11.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/jupyter/.local/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.12.1)\n",
      "Requirement already satisfied: six in /home/jupyter/.local/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.15.0)\n",
      "Requirement already satisfied: termcolor in /home/jupyter/.local/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.56.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.28.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/jupyter/.local/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.50.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /home/jupyter/.local/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.1->kfp) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.1->kfp) (59.8.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.7/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.11)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2022.9.24)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<20,>=8.0.0->kfp) (1.4.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<20,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform) (3.0.9)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp) (3.10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<20,>=8.0.0->kfp) (3.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install {USER_FLAG} --upgrade \\\n",
    "google-cloud-aiplatform \\\n",
    "google-cloud-pipeline-components \\\n",
    "kfp && touch pip_installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f76ee-8169-41a7-bee5-78a6e4904cc9",
   "metadata": {},
   "source": [
    "## Restart the Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48567db6-06b8-45db-8082-1cab2c58963d",
   "metadata": {},
   "source": [
    "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633b44c2-2043-4296-91a2-38f140b9a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73090c-b4b9-4af5-8574-0003a5caab07",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91da6d95-70a2-40a6-8021-bc47576597b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.18'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import kfp\n",
    "\n",
    "from google_cloud_pipeline_components.experimental.custom_job import utils\n",
    "import google.cloud.aiplatform as aip\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import component\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "kfp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a821da-f7c5-4411-939e-93a35c88147d",
   "metadata": {},
   "source": [
    "## Set up Project Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18fe9e8-561a-4562-8482-d62b133d74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"bq-experiments-350102\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"bq-experiments-fraud\" \n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d546ad-8bb6-45f9-954d-5384f450ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 493534783  2022-08-25T16:24:56Z  gs://bq-experiments-fraud/synthetic-fraud.csv#1661444696515532  metageneration=1\n",
      "      2131  2022-12-26T20:22:37Z  gs://bq-experiments-fraud/trainer_fraud.tar.gz#1672086157845914  metageneration=1\n",
      "                                 gs://bq-experiments-fraud/1skm4wti/\n",
      "                                 gs://bq-experiments-fraud/k49hwjyi/\n",
      "                                 gs://bq-experiments-fraud/mqmcvfd2/\n",
      "                                 gs://bq-experiments-fraud/phk9joqs/\n",
      "                                 gs://bq-experiments-fraud/pipeline_root/\n",
      "                                 gs://bq-experiments-fraud/pipelines/\n",
      "                                 gs://bq-experiments-fraud/q0pjoruv/\n",
      "                                 gs://bq-experiments-fraud/vy5rkufq/\n",
      "TOTAL: 2 objects, 493536914 bytes (470.67 MiB)\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b668fb-5db1-4caa-a8ca-cff47d050481",
   "metadata": {},
   "source": [
    "## Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8254131-70ac-4bb9-a26b-e436b1f4ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17310f-5b45-402f-9171-fd60e5f833fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Service Account Access for Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c04fcf0-88aa-4926-b488-9ccf22290498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes made to gs://bq-experiments-fraud/\n",
      "No changes made to gs://bq-experiments-fraud/\n"
     ]
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = \"402374189238-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "# Give storage access permissions\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67cacd-6282-4c45-9829-2813211e306c",
   "metadata": {},
   "source": [
    "## Set Pre-built Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c335f3-9a92-42ae-9902-16dd93cd115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-docker.pkg.dev/vertex-ai/training/xgboost-cpu.1-1:latest\n",
      "us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-1:latest\n"
     ]
    }
   ],
   "source": [
    "TRAIN_VERSION = \"xgboost-cpu.1-1\"\n",
    "DEPLOY_VERSION = \"xgboost-cpu.1-1\"\n",
    "\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(TRAIN_IMAGE)\n",
    "print(DEPLOY_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0451f57-48f9-4d42-a60b-e3604f73d58b",
   "metadata": {},
   "source": [
    "## Set Machine Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dc0ef92-bb93-4915-ac2e-7aabd0e97565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train machine type n1-standard-8\n"
     ]
    }
   ],
   "source": [
    "MACHINE_TYPE = \"n1-standard\"\n",
    "VCPU = \"8\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57674bd2-5da2-447c-a8f5-86db683ae1d3",
   "metadata": {},
   "source": [
    "### Helper to generate UUIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5487ff44-a96a-42ac-8e14-bcdf8b735c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713217e8-ed26-4253-9e40-048f4b6b7962",
   "metadata": {},
   "source": [
    "## Create Model Training Single Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e49b90cf-7343-4545-9d00-396bc58c05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"xgboost\", \"pandas\", \"scikit-learn==1.0.2\",\"fsspec\", \"gcsfs\", \"google-cloud-bigquery\", \"db_dtypes\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Main train function\n",
    "def custom_train_model(\n",
    "    model_dir: str,\n",
    "    bq_table: str,\n",
    "    project_id: str,\n",
    "    max_depth: int = 3,\n",
    "    learning_rate: float = 0.1,\n",
    "):\n",
    "    import datetime\n",
    "    import os\n",
    "    import subprocess\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    import xgboost as xgb\n",
    "    import argparse\n",
    "    import logging\n",
    "    import numpy as np\n",
    "    import json\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import f1_score\n",
    "    from google.cloud import bigquery\n",
    "    \n",
    "    \n",
    "    # Function to retrieve data from BigQuery\n",
    "    def get_data(project_id, bq_table):\n",
    "        logging.info(\"Downloading training data from BigQuery: {}, {}\".format(project_id, bq_table))\n",
    "        logging.info(\"Creating BigQuery client\")\n",
    "        bqclient = bigquery.Client(project=project_id)\n",
    "\n",
    "        logging.info(\"Loading table data\")\n",
    "        table = bigquery.TableReference.from_string(bq_table)\n",
    "        rows = bqclient.list_rows(table)\n",
    "        dataframe = rows.to_dataframe()\n",
    "\n",
    "        logging.info(\"Preparing data for training\")\n",
    "        dataframe[\"isFraud\"] = dataframe[\"isFraud\"].astype(int)\n",
    "        dataframe.drop(['nameOrig','nameDest','isFlaggedFraud'],axis=1,inplace=True)\n",
    "        X = pd.concat([dataframe.drop('type', axis=1), pd.get_dummies(dataframe['type'])], axis=1)\n",
    "        y = X[['isFraud']]\n",
    "        X = X.drop(['isFraud'],axis=1)\n",
    "\n",
    "        print(\"Splitting data for training\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=42, shuffle=True)\n",
    "\n",
    "        logging.info(\"Finishing get_data\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    # Function to train the model\n",
    "    def train_model(X_train, y_train, max_depth, learning_rate):\n",
    "        logging.info(\"Start training ...\")\n",
    "        model = xgb.XGBClassifier(\n",
    "                scale_pos_weight=734,\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        logging.info(\"Training completed\")\n",
    "        return model\n",
    "\n",
    "    # Function to evaluate the model\n",
    "    def evaluate_model(model, X_test, y_test):\n",
    "        logging.info(\"Preparing test data ...\")\n",
    "        data_test = xgb.DMatrix(X_test)\n",
    "\n",
    "        logging.info(\"Getting test predictions ...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Evaluating predictions ...\")\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        logging.info(f\"Evaluation completed with weighted f1 score: {f1}\")\n",
    "\n",
    "        logging.info(\"Finishing ...\")\n",
    "        return f1\n",
    "\n",
    "    # Start of function\n",
    "    logging.info(\"Component start\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_data(project_id, bq_table)\n",
    "    print(\"Training the model\")\n",
    "    model = train_model(X_train, y_train, max_depth, learning_rate)\n",
    "    print(\"Evaluating the model\")\n",
    "    f1 = evaluate_model(model, X_test, y_test)\n",
    "    metric_dict = {'f1_score': f1}\n",
    "\n",
    "    # GCSFuse conversion\n",
    "    gs_prefix = 'gs://'\n",
    "    gcsfuse_prefix = '/gcs/'\n",
    "    if model_dir.startswith(gs_prefix):\n",
    "        args.model_dir = model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "        dirpath = os.path.split(model_dir)[0]\n",
    "        if not os.path.isdir(dirpath):\n",
    "            os.makedirs(dirpath)\n",
    "\n",
    "    # Export the classifier to a file\n",
    "    gcs_model_path = os.path.join(model_dir, 'model.bst')\n",
    "    logging.info(\"Saving model artifacts to {}\". format(gcs_model_path))\n",
    "    model.save_model(gcs_model_path)\n",
    "\n",
    "    logging.info(\"Saving metrics to {}/metrics.json\". format(model_dir))\n",
    "    gcs_metrics_path = os.path.join(args.model_dir, 'metrics.json')\n",
    "    with open(gcs_metrics_path, \"w\") as f:\n",
    "        f.write(json.dumps(metric_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ed832f15-6028-42a3-ac54-15801c61f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_job_training_op = utils.create_custom_training_job_op_from_component(\n",
    "    custom_train_model, replica_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0377c9-bafa-4ab5-9092-46827e9aa503",
   "metadata": {},
   "source": [
    "## Construct Custom Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cec830-5892-452c-aa9f-340525b6261a",
   "metadata": {},
   "source": [
    "Construct a pipeline for training a custom model using pre-built Google Cloud Pipeline Components for Vertex AI Training, as follows:\n",
    "\n",
    "1. Pipeline arguments, specify the locations of:\n",
    "- **python_package:** The custom training Python package.\n",
    "- **python_module:** The entry module in the package to execute.\n",
    "- **display_name:** The human readable resource name for generated resources\n",
    "- **bucket:** The Cloud Storage location to store model artifacts\n",
    "- **project:** The project ID.\n",
    "- **region:** The region.\n",
    "\n",
    "2. Use the prebuilt component CustomPythonPackageTrainingJobRunOp to train a custom model and upload the custom model as a Vertex AI Model resource, where:\n",
    "- The display name for the model.\n",
    "- The dataset is specified within the training package.\n",
    "- The python package are passed into the pipeline.\n",
    "- The command line arguments for the python package are hardcoded in the call to the component.\n",
    "- The command line arguments for the name of the experiment and run are hardcoded in the call to the component.\n",
    "- The training and serving containers are specified in the pipeline definition.\n",
    "- The component returns the model resource as outputs[\"model\"].\\\n",
    "\n",
    "Note: Since each component is executed as a graph node in its own execution context, you pass the parameter project for each component op, in constrast to doing a aip.init(project=project) if this was a Python script calling the SDK methods directly within the same execution context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d234d50c-17cb-482f-a5dc-cec000a16a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"{}/pipeline_root/custom_xgboost_training\".format(BUCKET_URI)\n",
    "MODEL_DIR = BUCKET_URI + \"/model\"\n",
    "BQ_TABLE = \"bq-experiments-350102.synthetic_financial_fraud.fraud_data\"\n",
    "MAX_DEPTH=1\n",
    "LEARNING_RATE=6e-8\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"fraud-xgboost\",\n",
    "    description=\"Train and deploy a custom XGBoost model for fraud detection\",\n",
    ")\n",
    "def pipeline(\n",
    "    model_dir: str = MODEL_DIR,\n",
    "    bq_table: str = BQ_TABLE,\n",
    "    project_id: str = PROJECT_ID,\n",
    "    max_depth: int = 1,\n",
    "    learning_rate: float = 6e-8,\n",
    "):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    _ = custom_job_training_op(\n",
    "            model_dir=model_dir,\n",
    "            bq_table = bq_table,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            project_id=project_id,\n",
    "            project=PROJECT_ID,\n",
    "            location=REGION,\n",
    "            base_output_directory=PIPELINE_ROOT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7e86a-3434-423b-b66a-987b5aa274c8",
   "metadata": {},
   "source": [
    "## Compile and Execute The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f10af8d4-aa13-4b89-8b38-c67c92f1ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"custom_xgboost_training.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc4e73-66e8-4723-9427-7acba57c1da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/402374189238/locations/us-central1/pipelineJobs/fraud-xgboost-20221227185850\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/402374189238/locations/us-central1/pipelineJobs/fraud-xgboost-20221227185850')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/fraud-xgboost-20221227185850?project=402374189238\n",
      "PipelineJob projects/402374189238/locations/us-central1/pipelineJobs/fraud-xgboost-20221227185850 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/402374189238/locations/us-central1/pipelineJobs/fraud-xgboost-20221227185850 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/402374189238/locations/us-central1/pipelineJobs/fraud-xgboost-20221227185850 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/402374189238/locations/us-central1/pipelineJobs/fraud-xgboost-20221227185850 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/402374189238/locations/us-central1/pipelineJobs/fraud-xgboost-20221227185850 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "pipeline = aip.PipelineJob(\n",
    "    display_name=\"custom_xgboost_fraud\",\n",
    "    template_path=\"custom_xgboost_training.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "pipeline.run(service_account=SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c94063-04e7-4a9e-bac8-6ac22f51dc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
